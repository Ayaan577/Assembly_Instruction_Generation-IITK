{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdj4IugMqpZibIwP9PXzzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f7936729b4b428894d144ec30bb20c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_014ba4073d3e4a1eba5439621f1baba4",
              "IPY_MODEL_64200baff75f4181bb9e948782123701",
              "IPY_MODEL_90955af4a8a14adba89ee671eaf1ae2b"
            ],
            "layout": "IPY_MODEL_00b47aedb5414b5e819fc60d79406aa4"
          }
        },
        "014ba4073d3e4a1eba5439621f1baba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90debf3eb4d5482ea06dadfefbdac849",
            "placeholder": "​",
            "style": "IPY_MODEL_6f48063e7f724ce8a468149d798487fd",
            "value": "Map: 100%"
          }
        },
        "64200baff75f4181bb9e948782123701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ec8e84e41c4126ad7e0d8f2e251229",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2bc4ee3914247348680a0b5b447bcae",
            "value": 10000
          }
        },
        "90955af4a8a14adba89ee671eaf1ae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14dd0f5782de45e99ed3ace1e65e926c",
            "placeholder": "​",
            "style": "IPY_MODEL_9c45ed5a15c049729f3551d22e59af95",
            "value": " 10000/10000 [00:05&lt;00:00, 1952.60 examples/s]"
          }
        },
        "00b47aedb5414b5e819fc60d79406aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90debf3eb4d5482ea06dadfefbdac849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f48063e7f724ce8a468149d798487fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ec8e84e41c4126ad7e0d8f2e251229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bc4ee3914247348680a0b5b447bcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14dd0f5782de45e99ed3ace1e65e926c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c45ed5a15c049729f3551d22e59af95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayaan577/IITK-Internship/blob/main/Furniture_Assembly_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Cell 1: Install / Upgrade Dependencies\n",
        "# Colab Cell 1: Install HF libs without messing up core Colab packages\n",
        "!pip install --upgrade --quiet --no-deps transformers datasets tqdm\n",
        "\n",
        "\n",
        "# Colab Cell 2: Imports & GPU Check\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"No GPU found! Select T4 in Runtime > Change runtime type > GPU.\")\n",
        "print(\"Using GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0khixXS0d50",
        "outputId": "2d3e22a5-fff2-4d6e-8001-331ce26b3a3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, zipfile\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    T5Tokenizer, T5ForConditionalGeneration,\n",
        "    Trainer, TrainingArguments,\n",
        "    DataCollatorForSeq2Seq,  # Changed from DataCollatorWithPadding\n",
        "    EarlyStoppingCallback\n",
        ")"
      ],
      "metadata": {
        "id": "9j8zkmG00f13"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f7936729b4b428894d144ec30bb20c3",
            "014ba4073d3e4a1eba5439621f1baba4",
            "64200baff75f4181bb9e948782123701",
            "90955af4a8a14adba89ee671eaf1ae2b",
            "00b47aedb5414b5e819fc60d79406aa4",
            "90debf3eb4d5482ea06dadfefbdac849",
            "6f48063e7f724ce8a468149d798487fd",
            "67ec8e84e41c4126ad7e0d8f2e251229",
            "f2bc4ee3914247348680a0b5b447bcae",
            "14dd0f5782de45e99ed3ace1e65e926c",
            "9c45ed5a15c049729f3551d22e59af95"
          ]
        },
        "id": "CxZTAsbLz_g9",
        "outputId": "0ccc1c7b-386c-4397-9a62-2e538a2e0291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from: /content/furniture_dataset/furniture_10000_enhanced.jsonl\n",
            "Loaded 10000 samples (out of 100k) for speed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7936729b4b428894d144ec30bb20c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c0863f5ba13a>:86: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2815' max='2815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2815/2815 10:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.205300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.173600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.157400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.127700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.119700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.108800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.104900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.083600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.083300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.080600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.077400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.074500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.063200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.065300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/furniture_t5_model_final/ (stored 0%)\n",
            "  adding: content/furniture_t5_model_final/model.safetensors (deflated 8%)\n",
            "  adding: content/furniture_t5_model_final/spiece.model (deflated 48%)\n",
            "  adding: content/furniture_t5_model_final/generation_config.json (deflated 29%)\n",
            "  adding: content/furniture_t5_model_final/added_tokens.json (deflated 83%)\n",
            "  adding: content/furniture_t5_model_final/tokenizer_config.json (deflated 94%)\n",
            "  adding: content/furniture_t5_model_final/config.json (deflated 62%)\n",
            "  adding: content/furniture_t5_model_final/special_tokens_map.json (deflated 85%)\n",
            "  adding: content/furniture_t5_model_final/training_args.bin (deflated 52%)\n"
          ]
        }
      ],
      "source": [
        "# Colab Cell 3: Unzip the dataset\n",
        "zip_path = \"/content/furniture_10000_enhanced.zip\"\n",
        "extract_dir = \"/content/furniture_dataset\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# Find the JSONL\n",
        "files = [f for f in os.listdir(extract_dir) if f.endswith(\".jsonl\")]\n",
        "if not files:\n",
        "    raise FileNotFoundError(\"No .jsonl file found in the zip!\")\n",
        "jsonl_path = os.path.join(extract_dir, files[0])\n",
        "print(\"Loading from:\", jsonl_path)\n",
        "\n",
        "# Colab Cell 4: Read first 10k samples from JSONL\n",
        "max_samples = 10_000\n",
        "data = []\n",
        "with open(jsonl_path, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= max_samples:\n",
        "            break\n",
        "        data.append(json.loads(line))\n",
        "print(f\"Loaded {len(data)} samples (out of 100k) for speed\")\n",
        "\n",
        "# Prepare inputs/targets\n",
        "inputs  = [item['linearized'] for item in data]\n",
        "targets = [\" \".join(item['instructions']) for item in data]\n",
        "\n",
        "# Build HF Dataset\n",
        "raw_ds = Dataset.from_dict({\"input_text\": inputs, \"target_text\": targets})\n",
        "\n",
        "# Colab Cell 5: Tokenizer & Model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer  = T5Tokenizer.from_pretrained(model_name)\n",
        "model      = T5ForConditionalGeneration.from_pretrained(model_name).cuda()\n",
        "\n",
        "# Colab Cell 6: Preprocessing + Dataset Split\n",
        "max_input_length  = 256\n",
        "max_target_length = 256\n",
        "\n",
        "def preprocess_fn(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"input_text\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True\n",
        "    )\n",
        "    # Tokenize targets with the 'text_target' argument\n",
        "    labels = tokenizer(\n",
        "        text_target=examples[\"target_text\"],\n",
        "        max_length=max_target_length,\n",
        "        truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized = raw_ds.map(preprocess_fn, batched=True, remove_columns=[\"input_text\",\"target_text\"])\n",
        "\n",
        "# Proper train-test split\n",
        "split_dataset = tokenized.train_test_split(test_size=0.1)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "eval_dataset = split_dataset[\"test\"]\n",
        "\n",
        "# Correct data collator for seq2seq\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Colab Cell 7: TrainingArguments (compatible with your transformers)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/furniture_t5_model\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    save_steps=500,           # checkpoint every 500 steps\n",
        "    eval_steps=500,           # evaluate every 500 steps\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"/content/furniture_t5_model/logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Colab Cell 8: Trainer without early stopping\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    # no EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "\n",
        "# Colab Cell 9: Train!\n",
        "trainer.train()\n",
        "\n",
        "# Colab Cell 10: Save & Zip the Final Model\n",
        "trainer.save_model(\"/content/furniture_t5_model_final\")\n",
        "tokenizer.save_pretrained(\"/content/furniture_t5_model_final\")\n",
        "\n",
        "!zip -r furniture_t5_model_final.zip /content/furniture_t5_model_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_path = \"/content/furniture_t5_model_final\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path).cuda()\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "text_gen = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "# Use the hold-out evaluation dataset\n",
        "unseen_samples = eval_dataset[:10]  # Adjust this as needed\n",
        "# Decode inputs and targets from the tokenized dataset\n",
        "inputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in unseen_samples[\"input_ids\"]]\n",
        "targets = [tokenizer.decode(ids, skip_special_tokens=True) for ids in unseen_samples[\"labels\"]]\n",
        "\n",
        "# Generate predictions\n",
        "predictions = []\n",
        "for inp in inputs:\n",
        "    generated = text_gen(inp, max_length=256, num_beams=4, early_stopping=True)\n",
        "    predictions.append(generated[0][\"generated_text\"])\n",
        "\n",
        "# Display some examples\n",
        "for i in range(3):  # Show first 3 examples\n",
        "    print(f\"Input: {inputs[i]}\")\n",
        "    print(f\"Target: {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Vpbr-R8afD",
        "outputId": "432c263e-9b19-4750-a9f0-88557fd1908c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: (Bunk_bed (Frame) (Slats) (Mattress) (GuardRails) (Fasteners))\n",
            "Target: Insert GuardRails + Fasteners -> GuardRails_Fasteners_assembly Insert GuardRails_Fasteners_assembly + Mattress -> GuardRails_Fasteners_assembly_Mattress_assembly Combine GuardRails_Fasteners_assembly_Mattress_assembly + Slats -> GuardRails_Fasteners_assembly_Mattress_assembly_Slats_assembly Insert GuardRails_Fasteners_assembly_Mattress_assembly_Slats_assembly + Frame -> Finished_GuardRails_Fasteners_assembly_Mattress_assembly_Slats_assembly_Frame_assembly\n",
            "Prediction: Attach GuardRails + Slats -> GuardRails_Slats_assembly Combine GuardRails_Slats_assembly + Mattress -> GuardRails_Slats_assembly_Mattress_assembly Combine GuardRails_Slats_assembly_Mattress_assembly + Frame -> GuardRails_Slats_assembly_Mattress_assembly_Frame_assembly Combine GuardRails_Slats_assembly_Mattress_assembly_Frame_assembly + Fasteners -> Finished_GuardRails_Slats_assembly_Mattress_assembly_Frame_assembly_Fasteners_assembly\n",
            "--------------------------------------------------\n",
            "Input: (Swing_seat (Seat) (HangingMechanism) (Fasteners))\n",
            "Target: Insert HangingMechanism + Fasteners -> HangingMechanism_Fasteners_assembly Insert HangingMechanism_Fasteners_assembly + Seat -> Finished_HangingMechanism_Fasteners_assembly_Seat_assembly\n",
            "Prediction: Attach HangingMechanism + Seat -> HangingMechanism_Seat_assembly Combine HangingMechanism_Seat_assembly + Fasteners -> Finished_HangingMechanism_Seat_assembly_Fasteners_assembly\n",
            "--------------------------------------------------\n",
            "Input: (Console_table (Tabletop) (Legs) (Fasteners))\n",
            "Target: No assembly needed\n",
            "Prediction: Insert Tabletop + Legs -> Tabletop_Legs_assembly Attach Tabletop_Legs_assembly + Fasteners -> Finished_Tabletop_Legs_assembly_Fasteners_assembly\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CnEGZpP9R50",
        "outputId": "37df6a05-5b1e-4dbc-d191-29b4ee458682"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.2.6)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "# Calculate BLEU\n",
        "bleu_score = sacrebleu.corpus_bleu(predictions, [targets])\n",
        "print(\"BLEU Score:\", bleu_score.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTWPBs4y9T5r",
        "outputId": "c628b985-e98d-4f01-ab48-240e19b0394f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 56.36083868922011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC0l-W5j9YIv",
        "outputId": "9eda9792-4ce6-48dd-f4e5-5485e83d4e31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.2.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=10bbbc2043e290fd7620f895ae319b924ab682a3e50629e786fb3cc03aca2ad8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "# Calculate ROUGE for each prediction\n",
        "rouge_scores = [scorer.score(target, pred) for target, pred in zip(targets, predictions)]\n",
        "\n",
        "# Compute average scores\n",
        "avg_rouge = {\n",
        "    \"rouge1\": sum([score[\"rouge1\"].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
        "    \"rouge2\": sum([score[\"rouge2\"].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
        "    \"rougeL\": sum([score[\"rougeL\"].fmeasure for score in rouge_scores]) / len(rouge_scores),\n",
        "}\n",
        "\n",
        "print(\"ROUGE Scores:\", avg_rouge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQSf47nD9aIt",
        "outputId": "ee6e8a3f-cb35-4142-d828-79f215bc2056"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge1': 0.7760967003965311, 'rouge2': 0.3206089743589744, 'rougeL': 0.5860468033835567}\n"
          ]
        }
      ]
    }
  ]
}
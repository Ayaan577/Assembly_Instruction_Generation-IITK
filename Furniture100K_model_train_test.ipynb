{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, json, zipfile\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from transformers import pipeline\n",
        "import random\n",
        "import pandas as pd\n",
        "!pip install rouge-score --quiet\n",
        "from rouge_score import rouge_scorer\n",
        "!pip install sacrebleu --quiet\n",
        "import sacrebleu"
      ],
      "metadata": {
        "id": "A9vMzKGZliqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5f7774-a0ee-46b2-a5b7-6baebe4767cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq, TrainingArguments, Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")"
      ],
      "metadata": {
        "id": "gS7iwUTav5dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B97BWMnFk37D",
        "outputId": "9e3a7d54-3ef7-4e9d-c152-45554a28c8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100000 samples.\n"
          ]
        }
      ],
      "source": [
        "# Unzip (if not already)\n",
        "zip_path    = \"/content/furniture_dataset.zip\"\n",
        "extract_dir = \"/content/furniture_full\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# Find JSONL\n",
        "jsonl = next(f for f in os.listdir(extract_dir) if f.endswith(\".jsonl\"))\n",
        "jsonl_path = os.path.join(extract_dir, jsonl)\n",
        "\n",
        "# Read all data\n",
        "data = []\n",
        "with open(jsonl_path) as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "print(f\"Loaded {len(data)} samples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convert to dict lists\n",
        "inputs  = [d[\"linearized\"] for d in data]\n",
        "targets = [\" \".join(d[\"instructions\"]) for d in data]\n",
        "\n",
        "# 80/10/10 split\n",
        "train_in, temp_in, train_tg, temp_tg = train_test_split(inputs, targets, test_size=0.2, random_state=42)\n",
        "val_in,  test_in,  val_tg,  test_tg  = train_test_split(temp_in, temp_tg, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build HF DatasetDict\n",
        "train_ds = Dataset.from_dict({\"input_text\": train_in, \"target_text\": train_tg})\n",
        "val_ds   = Dataset.from_dict({\"input_text\": val_in,   \"target_text\": val_tg})\n",
        "test_ds  = Dataset.from_dict({\"input_text\": test_in,  \"target_text\": test_tg})\n",
        "\n",
        "dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNWvXJZkllnQ",
        "outputId": "ed349bdd-0265-49da-bb31-1791bee1a566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_text', 'target_text'],\n",
            "        num_rows: 80000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_text', 'target_text'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_text', 'target_text'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model     = T5ForConditionalGeneration.from_pretrained(\"t5-small\").cuda()\n",
        "\n",
        "max_in, max_tg = 256, 256\n",
        "\n",
        "def preprocess(ex):\n",
        "    mi = tokenizer(ex[\"input_text\"],  max_length=max_in,  truncation=True, padding=\"max_length\")\n",
        "    la = tokenizer(text_target=ex[\"target_text\"], max_length=max_tg, truncation=True, padding=\"max_length\")\n",
        "    mi[\"labels\"] = la[\"input_ids\"]\n",
        "    return mi\n",
        "\n",
        "tokenized = dataset.map(preprocess, batched=True, remove_columns=[\"input_text\",\"target_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "3a1d2aca5f5d4253aaef9640e9efbd3e",
            "689b4ee9369340d0ab6671d25aecf117",
            "bccaa95dc9b64f358c57926c2c5d3fd6",
            "d661020e4fae4283afae5a75fdbc2b19",
            "584981c8ce6f4d1cbec23b5efeb58821",
            "0b116ca0f0524bca9bc90a3086dba1ca",
            "38c0764db3ce40f5adcc6eff7af5daf4",
            "a5f5363ea7cf466886b82ddd34dff68f",
            "9bd538952a484f2ca58d22d29cda2467",
            "afddec2a33b54d48a5c9cd4bedf2ce14",
            "53332300533442428742163527eb7390",
            "e4c94459cef849e390892936679c1114",
            "27c771ddc1a548afb18c1532332d71ba",
            "82697e072f424984846f984c9e8d986f",
            "6bd44efa495a45e7a0624f6f3c0db15b",
            "b6b795068a3b4356b03f31b0891ca247",
            "1a505ec418874ccf9830f03005b75899",
            "a346d737289e436b8590811306bd5e96",
            "b2e3f086d0944399abb3289e702f1813",
            "c55dc81008904580ac21e8893c023042",
            "08382a0847ee48f5a4449537eb0b9554",
            "a1cbb29de2954869b6fd53c31a62ff16",
            "4c2d55b36adb4d56a32d2c9f8d37b9ec",
            "f27135c164a04e828eb61f3ef6d71695",
            "4b12c06e02c54a99baa360c17555c577",
            "8fafc0e8f5f34e04af059c0d1f166bda",
            "1edc89d7bba74c18b2dd69843079cad6",
            "35ce97db196344778f6230e33c2512df",
            "b985a97b0653451f9dd328436519f4eb",
            "1ae500b9612d487891ab64a1a73b718f",
            "aa57f2a4395e41bb991215cfaa509621",
            "041a31f9b62f4d5d9dc03e789ce6b207",
            "95f46318b16e442e8f3761c87c58312f",
            "e2f2dc66f4654c83a75d9ceffa05f2cc",
            "291269bf69af423ea785f0d59c38cec0",
            "c887f9d1fcba48d889de4fd31e613f12",
            "e5158a6f095945eaa2d09734bf0fc1ec",
            "47d7d069f5db4c56bd4f641f2f9dc178",
            "14d6fdc709034bba8c29d897c478deb4",
            "a0677e93646348d6859db7168263eed9",
            "90ffbdd6f4d143a8ad00ae7326e93d0a",
            "ddc405c0b5434cd49e61143cc4c48118",
            "186a84028b2847288df6aa890c899bc9",
            "ec3ca1a1112749689556314a30adaeed",
            "d415529558fd4f21af1622bc211d8074",
            "177ad86e1f6b4fdcb49cb989509e16a7",
            "78e9390af2a4433d8c133b6e51fb2c6e",
            "b6f83f4f74334f8b913476f2f3e209c3",
            "87231468b6254bb5842884d854513358",
            "1dd1f31fa21b49dcab54386186fafdeb",
            "3d81a121a57e4fc5ac488c6b4d9fb88c",
            "77182171c9984691b0034b93d2f10b6d",
            "7c5c6f2d830d444eacadeb263dc275ad",
            "38a1a466d5c242538dc6f10f76eece4a",
            "56dd08450f4544e09150195d970c9fac",
            "11fdf4983007413fbe88b1818d200bf1",
            "509b64e88c1046639f80c0281e56dfa6",
            "a9870ecd2fc6440d859ea9b0794e6d32",
            "358b0b1326a54b5792f1165c5c094c09",
            "64f221d1efa94d35a17d62c0a7a325ed",
            "5ae980d47d004064a16720a5afc08809",
            "91df7857d34b44e885d2ac1f51261f48",
            "e2bb599cd2f64533ad33fce5429a5a26",
            "8951d1011b314717a3873186de804d63",
            "4a7d41de69774bc995e52e772e83cc1a",
            "c0324cbd07e84e0d8c33c25844d737f1",
            "5eb4d82f3b2e45ee8d5b27860b6bd21d",
            "7704ba52c63b418d91b6aa207f83010d",
            "8f95a2a5f746462988fbabb18ea77b21",
            "012182757db44e129a683f7c9fdfce2d",
            "907a1eb59ce74b4a9f760946a27f5604",
            "b6e5b6f0ebc04a8f8c74bbfe16e25412",
            "ab0f8255f1214345adfce8c519740a08",
            "dbf6171f694e4b4aa4cf5c2314878e65",
            "fefe8b2f8d2f426e86e509833b7d2eb1",
            "38aad91ab9ee410688aea120fe139d69",
            "2003c695ef3c482b94275505e21a30a3",
            "871fe4a1708141f294c384a8fd632ff7",
            "43cb8fd140dd49d6be223255cec5b0d1",
            "be09dd9ff2d84557aac90b9e7ba90b75",
            "5022826cb58344189e7e7e720055cf14",
            "4cca1a4b3f224a1b9c1d493465bbc53f",
            "3b5dea02143648878c98b4676187c51a",
            "20f25fb5aeda4130aee4b4d7479641b6",
            "b3e0bf0d6c384b5fa86e908f02c3a56c",
            "fcf36e45836a4ff1b38a35463004346a",
            "de16966265f1448b8a80ece0b11fdc0b",
            "a88b22569a0646dd82220dac25b86834",
            "4ccb761c15f149bf89518d6d7cfe848d",
            "3f0131365ae0483fbaf09a1d77082722",
            "d6b3b35982b948ba93288ff3c438e2d1",
            "041580e1bd154d90a049970c58cf3a7f",
            "325576c13fcf46a8b3cc0fa3f1bb61d3",
            "8375777538a34d5dba5c70865c689f85",
            "6a7e1616b588436aadd4c6b71b77ce65",
            "27c15edde3184563a3a6ede9fa05c4d5",
            "248e1329ef3e4da58fec51d8b95a61a1",
            "084e78ad2f5b4151b1d363ea2296acdb",
            "61a0611f5d8944e486d6d0c4a595dff6"
          ]
        },
        "id": "IbZFk9gklp8w",
        "outputId": "b6769b85-7ce1-4bc8-db54-b66ac2ea9ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a1d2aca5f5d4253aaef9640e9efbd3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c94459cef849e390892936679c1114"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c2d55b36adb4d56a32d2c9f8d37b9ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2f2dc66f4654c83a75d9ceffa05f2cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d415529558fd4f21af1622bc211d8074"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11fdf4983007413fbe88b1818d200bf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eb4d82f3b2e45ee8d5b27860b6bd21d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "871fe4a1708141f294c384a8fd632ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ccb761c15f149bf89518d6d7cfe848d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/furniture_full_t5\",\n",
        "    num_train_epochs=3,               # up to 8 epochs\n",
        "    per_device_train_batch_size=3,\n",
        "    gradient_accumulation_steps=2,     # effective batch size = 16\n",
        "    per_device_eval_batch_size=8,\n",
        "    save_steps=1000,                   # checkpoint every 1 000 steps\n",
        "    eval_steps=1000,                   # evaluate every 1 000 steps\n",
        "    save_total_limit=3,\n",
        "    logging_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=3e-4,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 3) Trainer without early stopping or best-model loading\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/furniture_full_t5_final\")\n",
        "tokenizer.save_pretrained(\"/content/furniture_full_t5_final\")\n"
      ],
      "metadata": {
        "id": "1275lEaalqT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4761d028-bf44-430a-8584-f00add8676b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-cf6e49e28b18>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40002' max='40002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40002/40002 1:59:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.277200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18400</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18800</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20600</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25200</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25400</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/furniture_full_t5_final/tokenizer_config.json',\n",
              " '/content/furniture_full_t5_final/special_tokens_map.json',\n",
              " '/content/furniture_full_t5_final/spiece.model',\n",
              " '/content/furniture_full_t5_final/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generator = pipeline(\"text2text-generation\",\n",
        "                     model=\"/content/furniture_full_t5_final\",\n",
        "                     tokenizer=tokenizer,\n",
        "                     device=0)\n",
        "\n",
        "# Prepare test inputs & targets\n",
        "test_inputs  = test_ds[\"input_text\"]\n",
        "test_targets = test_ds[\"target_text\"]\n",
        "\n",
        "# Generate predictions (you can batch this for speed)\n",
        "preds = [generator(\"assemble: \"+inp, max_new_tokens=128, num_beams=4)[0][\"generated_text\"]\n",
        "         for inp in test_inputs[:1000]]  # you can evaluate all or a subset\n",
        "\n",
        "refs = test_targets[:len(preds)]\n",
        "\n",
        "# Compute BLEU\n",
        "bleu = sacrebleu.corpus_bleu(preds, [refs]).score\n",
        "print(\"BLEU:\", bleu)\n",
        "\n",
        "# Compute ROUGE\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\",\"rouge2\",\"rougeL\"], use_stemmer=True)\n",
        "scores = [scorer.score(r, p) for r,p in zip(refs, preds)]\n",
        "avg = {k: sum(d[k].fmeasure for d in scores)/len(scores) for k in scores[0]}\n",
        "print(\"ROUGE:\", avg)\n"
      ],
      "metadata": {
        "id": "VupBdjYFlw_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41abbf87-e00f-4211-8d85-94e5ddd9804b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 80.38054119856658\n",
            "ROUGE: {'rouge1': 0.927062151617313, 'rouge2': 0.925215166830592, 'rougeL': 0.927062151617313}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING ON UNSEEN DATA**"
      ],
      "metadata": {
        "id": "9QOH69Q0JoC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, json\n",
        "from datasets import Dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
        "\n",
        "# Step 1a: Unzip\n",
        "zip_path    = \"/content/furniture_10000_enhanced.zip\"\n",
        "extract_dir = \"/content/furniture_testset\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# Step 1b: Locate JSONL\n",
        "jsonl_files = [f for f in os.listdir(extract_dir) if f.endswith(\".jsonl\")]\n",
        "assert jsonl_files, \"No .jsonl file found in the zip!\"\n",
        "test_jsonl = os.path.join(extract_dir, jsonl_files[0])\n",
        "\n",
        "# Step 1c: Read into lists\n",
        "inputs, targets = [], []\n",
        "with open(test_jsonl) as f:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "        inputs.append(obj[\"linearized\"])\n",
        "        # join instructions back to a single string\n",
        "        targets.append(\" \".join(obj[\"instructions\"]))\n",
        "\n",
        "print(f\"Loaded {len(inputs)} unseen test samples.\")\n"
      ],
      "metadata": {
        "id": "umLNF3Iel3-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d9125d-5851-40f7-d48a-8c1453df9475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10000 unseen test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/furniture_full_t5_final\"  # or wherever you saved the final zip\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
        "model     = T5ForConditionalGeneration.from_pretrained(model_dir).cuda()\n",
        "\n",
        "# Create a generation pipeline\n",
        "generator = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    max_new_tokens=256,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "MxGY1bmbmh_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a9c27d-5603-4040-b4ac-96dfb3aa54ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare full list of prompts\n",
        "prompts = [\"assemble: \" + tree for tree in inputs]\n",
        "\n",
        "# Generate everything in batches of 32\n",
        "batch_size = 32\n",
        "all_outputs = generator(prompts, batch_size=batch_size)\n",
        "\n",
        "# Extract the generated texts\n",
        "predictions = [out[\"generated_text\"] for out in all_outputs]\n",
        "\n"
      ],
      "metadata": {
        "id": "Ray3EzpAdgs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU\n",
        "bleu = sacrebleu.corpus_bleu(predictions, [targets]).score\n",
        "print(f\"Unseen Test BLEU: {bleu:.2f}\")\n",
        "\n",
        "# ROUGE\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\",\"rouge2\",\"rougeL\"], use_stemmer=True)\n",
        "scores = [scorer.score(tgt, pred) for tgt, pred in zip(targets, predictions)]\n",
        "avg_rouge = {\n",
        "    \"rouge1\": sum(s[\"rouge1\"].fmeasure for s in scores) / len(scores),\n",
        "    \"rouge2\": sum(s[\"rouge2\"].fmeasure for s in scores) / len(scores),\n",
        "    \"rougeL\": sum(s[\"rougeL\"].fmeasure for s in scores) / len(scores),\n",
        "}\n",
        "print(\"Unseen Test ROUGE:\", {k: f\"{v:.3f}\" for k,v in avg_rouge.items()})\n"
      ],
      "metadata": {
        "id": "AVWEdfIadkxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
